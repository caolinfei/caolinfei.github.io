<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2019%2F11%2F09%2F14Java8%2F</url>
    <content type="text"><![CDATA[Lambda##介绍 ​ Lambda可以看作为把方法当作参数来传递 入参为接口的时候，可以使用Lambda，与C#不同 C#可以使用参数列表和返回值进行推断的 函数接口，一个方法只有一个方法， 可以使用注解@FunctionnaInterface 加了直接之后就会由限制 默认提供的Lambda接口有： java.util.fuction 下由提供好的lambda接口 接口的变化 默认方法 静态方法 ​ 可以理解为将println()的方法当做是接口的实现类 Optional​ 尽量优化空指针异常,但是Optional的返回null的时候 直接get也是会返回NullPointException &gt;创建Optional对象的几个方法： &gt;1. Optional.of(T value)， 返回一个Optional对象，value不能为空，否则会出空指针异常 &gt;2. Optional.ofNullable(T value)， 返回一个Optional对象，value可以为空 &gt;3. Optional.empty()，代表空 &gt;其他API: &gt;1. optional.isPresent()，是否存在值（不为空） &gt;2. optional.ifPresent(Consumer&lt;? super T&gt; consumer), 如果存在值则执行consumer &gt;3. optional.get()，获取value &gt;4. optional.orElse(T other)，如果没值则返回other &gt;5. optional.orElseGet(Supplier&lt;? extends T&gt; other)，如果没值则执行other并返回 &gt;6. optional.orElseThrow(Supplier&lt;? extends X&gt; exceptionSupplier)，如果没值则执行exceptionSupplier， &gt;并抛出异常 &gt; &gt;Stream 可以理解为一个管道流,所有的数据从这个管道内流动 每个方法相当于一个过滤,最终Collect(); Java 8 中的 Stream 是对集合（Collection）对象功能的增强，它专注于对集合对象进行各种非常便利、高效的聚合操作（aggregate operation），或者大批量数据操作 (bulk data operation)。Stream API 借助于同样新出现的 Lambda 表达式，极大的提高编程效率和程序可读性。同时它提供串行和并行两种模式进行汇聚操作，并发模式能够充分利用多核处理器的优势，使用 fork/join 并行方式来拆分任务和加速处理过程。通常编写并行代码很难而且容易出错, 但使用 Stream API 无需编写一行多线程的代码，就可以很方便地写出高性能的并发程序。所以说，Java 8 中首次出现的 java.util.stream 是一个函数式语言+多核时代综合影响的产物。在传统的 J2EE 应用中，Java 代码经常不得不依赖于关系型数据库的操作如：取平均值、取最大最小值、取汇总值、或者进行分组等等类似的这些操作。但在当今这个数据大爆炸的时代，在数据来源多样化、数据海量化的今天，很多时候不得不脱离 RDBMS，或者以底层返回的数据为基础进行更上层的数据统计。而 Java 的集合 API 中，仅仅有极少量的辅助型方法，更多的时候是程序员需要用 Iterator 来遍历集合，完成相关的聚合应用逻辑。这是一种远不够高效、笨拙的方法。在Java 7 中，如果要找一年级的所有学生，然后返回按学生分数值降序排序好的学生ID的集合，我们需要这样写： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556public class Student &#123;private Integer id; // IDprivate Grade grade; // ??private Integer score; // ??public Student(Integer id, Grade grade, Integer score) &#123;this.id = id;this.grade = grade;this.score = score;&#125;public Integer getId() &#123;return id;&#125;public void setId(Integer id) &#123;this.id = id;&#125;public Grade getGrade() &#123; return grade;&#125;public void setGrade(Grade grade) &#123;this.grade = grade;&#125;public Integer getScore() &#123;return score;&#125;public void setScore(Integer score) &#123;this.score = score;&#125;&#125;public enum Grade &#123;FIRST, SECOND, THTREE&#125;ublic static void main(String[] args) &#123;final Collection&lt;Student&gt; students = Arrays.asList(new Student(1, Grade.FIRST, 60),new Student(2, Grade.SECOND, 80),new Student(3, Grade.FIRST, 100));List&lt;Student&gt; gradeOneStudents = Lists.newArrayList();for (Student student: students) &#123;if (Grade.FIRST.equals(student.getGrade())) &#123;gradeOneStudents.add(student);&#125;&#125;Collections.sort(gradeOneStudents, new Comparator&lt;Student&gt;() &#123;@Overridepublic int compare(Student o1, Student o2) &#123;return o2.getScore().compareTo(o1.getScore());&#125;&#125;);List&lt;Integer&gt; studentIds = new ArrayList&lt;&gt;();for(Student t: gradeOneStudents)&#123;studentIds.add(t.getId());&#125;&#125; 而在 Java 8 使用 Stream，代码更加简洁易读；而且使用并发模式，程序执行速度更快。 123456789101112public static void main(String[] args) &#123;final Collection&lt; Student &gt; students= Arrays.asList(new Student(1, Grade.FIRST, 60),new Student(2, Grade.SECOND, 80),new Student(3, Grade.FIRST, 100));List&lt;Integer&gt; studentIds = students.stream().filter(student -&gt; student.getGrade().equals(Grade.FIRST)).sorted(Comparator.comparingInt(Student::getScore)).map(Student::getId).collect(Collectors.toList());&#125; Stream特点 1. Iterator，用户只能显式地一个一个遍历元素并对其执行某些操作；Stream，用户只要给出需要对其包含的元素执行什么操作，比如 “过滤掉长度大于 10 的字符串”、“获取每个字符串的首字母”等，Stream 会隐式地在内部进行遍历，做出相应的数据转换。 Stream 就如同一个Iterator，单向，不可往复，数据只能遍历一次，遍历过一次后即用尽了，就好比流水 从面前流过，一去不复返。 Stream 可以并行化操作，Iterator只能命令式地、串行化操作。顾名思义，当使用串行方式去遍历时，每个 item 读完后再读下一个 item。而使用并行去遍历时，数据会被分成多个段，其中每一个都在不同的线程中处理，然后将结果一起输出。Stream 的并行操作依赖于 Java7 中引入的 Fork/Join 框架来拆分任务和加速处理过程。 流的基本用法: ​ Map/flatMap ​ map: &gt;Stream&lt;String&gt; stream = Stream.&lt;String&gt;of(new String[]{&quot;a&quot;, &quot;b&quot;, &quot;c&quot;}); &gt;stream.map(String::toUpperCase).forEach(System.out::println); &gt; &gt;以上Map其实就是对数组内的元素进行操作 然后返回 &gt; &gt;flatMap: &gt; &gt; Stream&lt;List&lt;Integer&gt;&gt; inputStream = Stream.of( &gt;Arrays.asList(1), &gt;Arrays.asList(2, 3), &gt;Arrays.asList(4, 5, 6) &gt;); &gt;Stream&lt;Integer&gt; mapStream = inputStream.map(List::size); &gt;Stream&lt;Integer&gt; flatMapStream = inputStream.flatMap(Collection::stream); 打印输出123456 相当于合并 集合Join &gt; &gt;AllMatch() 所有都匹配返回True &gt; &gt;anyMatch()有一个匹配返回True &gt; &gt;NoneMatch 没有一个匹配返回True##并行Stream]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F06ELK%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F10mybatis%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F11linux%2F</url>
    <content type="text"></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F02java%E9%9B%86%E5%90%88%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[Java集合框架面视总结一:HashMapHashMap的数据结构 由数组和链表组成jdk1.8后添加的红黑树 负载因子: 当数组的使用率也就是bucket（桶）使用超过75% 0.75d的时候会扩容 扩容2倍 如果多线程在使用同一个hashMap正好都需要扩容这里有可能会造成链表的死循环 当桶内链表的节点数大于8的时候由链表转为红黑树 为什么要转为红黑树？ 当节点数量小于等于6的时候由红黑树转变为链表 初始容量16 数组的位置计算：`key.hasCode(）得到一个int的值\ HashMap Put方法做了哪些操作 Hash算法得到当前Key的Hash值 根据Hash值来计算当前的Node应该存储在数组的哪个 桶内 Hash算法为 当前key.hashCode()^key.hashCode()&gt;&gt;&gt;16高16位与低16位做异或运算 异或运算:按位“异或”操作符，如果两个数的二进制，相同位数只有一个是1，则该位结果是1，否则是0 例如: 5 ^ 4 5的二进制 0000 0000 0000 0101 ​ 4的二进制 0000 0000 0000 0100 根据规则 0000 0000 0000 0001 结果是2 根据HashCode的结果得到的Hash值 与当前容量大小 16 -1 做与运算 得到的 hash&amp;15 15的二进制是1111 因为做与运算 所以最小的值为0000 =&gt; 0 1111 =&gt; 15 区间正好落在 数组的索引内 而且在计算机内 与 &amp;预算的效率比取模更高一些 putval()当数组为空的时候 这个时候会调用resize()来初始化 oldCap原始容量为0 这个时候 设置 新的newCap newThr为 默认的容量也就是16 并且设置扩容的阈值 接下来Node&lt;K,V&gt;[] newTab = (Node&lt;K,V&gt;[])new Node[newCap]来进行初始化并且返回当前的初始化的newTab 存储数组 如果当前数组内没有存储任何数据那么直接存储 如果当前的数组存在数据 第一步先判断当前的需要存的hash 和key的值是否与 也就是说当前put的数据与之前存储的 key完全一样 (这里要注意 不一定hash值一样 key的值就一样 这里值就一样 也叫作hash碰撞),一样的情况下 将原来的节点值直接替换到 如果当前的节点与之前的不相同那么需要去判断 当前的节点是否是TreeNode 如果是TreeNode那么进行红黑树的插入 红黑树提高查询效率 如果不是红黑树的话 那么对当前的链表进行遍历 因为之前已经判断的第一个节点了说明第一个节点不相等 接下来 p.nex==null 如果成立 那么就将这个节点的next指向当前的新节点 然后判断是否大于的负载因子所计算的值 如果大于等于8那么当前的链表转换为红黑树 ​ ![1567048517956](typora-user-images\1567048517956.png) * 如果当前的节点也不为`Null`那么 继续判断节点是否和当前的值一致 ,如果一致的话直接Break了,后面有一个方法专门处理这种情况:下面这段代码 ![1567049257655](typora-user-images\1567049257655.png) ![1567049556438](typora-user-images\1567049556438.png) 进行容量判断是否大于扩容参数 进入扩容逻辑: 每次扩容都要 要求是2的N次幂 扩容的逻辑其实就是如果当前是红黑树 那么进行分割 ,是链表的话那么循环去处理 这里处理的时候 要跟新的容量还做与运算如果运算结果与之前一致那么位置不动不一致的然后移动到其他的桶内 注意事项 HasMap不是线程安全的 1将成员变量赋值给局部变量进行操作是为了不改版成员变量的结构 操作完后再去赋值给成员变量 2:HashMap,HashTable,ConCurruentHasMap,LinkendHasMapHashMap线程不安全的 HashTable 是基于Sync的锁 ConCurruentHasMap CAS +Sync CAS compare and swap 比较后交换]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F03JVM%2F</url>
    <content type="text"><![CDATA[JVM一:jvm介绍 Jvm是运行Java字节的码的软件(Java Virtual Machine) Java虚拟机, .java文件通过Javac编译成java字节码 .class文件,jvm通过加载.class文件来执行 二:运行时数据区(内存结构)1:方法区2:堆3栈4本地方法栈###5:程序计数器 ​ Java如何实现一次编译到处运行的呢 ​ 基于JVM屏蔽操作系统的差异,只需要编译成jvm认识的字节码 不同不同使用不同版本的Jvm jvm会把字节码翻译成 机器码来执行 ​ 三:ClassLoad BootStrapClassloader 加载核心类库的 ExtClassLoader 加载Java扩展库 AppClassload 加载程序员自己写的java类文件 自定义ClassLoader 定制化自己的类加载器 找到文件 读取流,然后调用DifienClass 然后可以直接把类加载进来 双亲委派机制; ​ 不同的类加载器负责不同的位置, 首先为从自定义的查找 如果自定义的加载过这个类,那么直接返回, 没有的话一级一级往上找 然后上层找不到下一层的一级一级的找]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F04%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%9B%B8%E5%85%B3%2F</url>
    <content type="text"><![CDATA[Java.until.ConCurruent 可重入锁 多线程累加 i=i+1 不是一个原子操作 可以增加volatile Thread/Runnable/Callable,future ​ 以上线程的使用方法; Callable是有返回值的 ​ Thread 在线程中合理的应用 责任链 ​ jps 显示当前Java进程 jstack 1234 显示当前进程的堆栈信息线程的状态** 6种状态 NEW 线程初始状态 没有调用Start方法 Runable 运行状态 Blocked 阻塞 Waiting 无限期等待 Time_Waiting 有限期等待 terminated 终止 线程的启动和终止 start Stop 暴力停止 interrupt 优雅方式终止 Volatile boolean isStop=false 线程安全问题 ​ 可见性 原子性 有序性 ​ 缓存一致性协议 MESI 嗅探机制 JMM 是为了屏蔽硬件层面的问题 来解决可见性原子性和有序性的问题 JMM定义了8个原子操作 ​ 首先Java访问了主内存 共享变量 不可以直接操作主内存, 必须赋值到工作内存. JMM抽象模型 JMM如何解决原子性可见性和有序性Volatile: 轻量的锁 解决可见性 防止指令重排序 CPU层面利用内存屏障来实现可见性,也就是解决指令重排序 Store Barrier 写屏障 Load load Barrier 读屏障 full Barrier 全屏障 编译器方面怎么防止指令重排序 Volatile 只可以解决可见性 没有办法解决原子性 Synchronized :可以解决原子性,可见性 顺序性 ,可以放在代码块 实例 类 ,同步阻塞 相当于串行执行,的阻塞的线程就会被CPU挂起 Sync的三种用法: ​ 1 sync(this) 锁定当前对象 当前的是列 访问方法被阻塞 其他实例不阻塞 sync(demo.class) 所有此对象的实例都会阻塞 方法名称 静态方法就是全局的 实例方法就是当前的是列 Synchornized:的实现原理 为什么每一个对象都可以成为锁 锁存在哪个地方 Javap 多了一个标示 ACC_SYNC 偏向锁=&gt;轻量级锁=&gt;重量级锁 ​]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F05Redis%2F</url>
    <content type="text"><![CDATA[1缓存为什么是高性能的 redis内部维护 IO多路复用程序, 了一个队列, 文件事件分派器,当请求到大 链接建立的时候,io多路复用程序会读取当前的执行命令 然后将其压入队列,文件分配器消费数据然后找到对应的处理器, 三个处理器 有链接应答 命令处理 命令回复, 理解IO多路复用机制: io多路复用大致是这样 一个线程负责轮询所有建立链接的Socket,某一个Socket有数据了 Redis支持的数据类型: ​ String Set List hash]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F08Spring%2F</url>
    <content type="text"><![CDATA[Spring的IOC​ IOC 是一种设计思想 控制翻转 DI(依赖注入)是IOC得一种实现. 支持的功能: 依赖注入 依赖检查 自动装配 支持集合 指定初始化和销毁方法 支持回调方法 BeanDefintion: 描述Bean的定义,解析XML以类名称为Key BeanDefinition为value存入到ConCurrentHashMap里 BeanFactory ​ Spring 父子容器 ApplicationContext Spring Refersh Spring的APO​ 根据动态代理来实现 如果是目标类实现了接口 那么使用JDK的,没有的话使用CGlib 可以没有类但是要有父类 Spring的事务]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F07Dubbo%2CZookeeper%2F</url>
    <content type="text"><![CDATA[dubbo##实现原理 十层分层原理 默认使用的Dubbo协议 长连接 异步IO/NIO的方式 ​ 大致的流程: 1Provider像注册中心注册自己,Consumer通过注册中心获取到Provider,他们俩之间通过代理来通信,Provider如果是集群的情况下,默认的Consumer以轮询的方式去实现负载均衡,代理之间通过Dubbo协议来实现通信, Dubbo的负载均衡策略: 随机 轮询 IPHas Dubbo的容错的策略,可以设置类级别 方法级别 failover cluste失败自动切换，自动重试其他机器，默认就是这个，常见于读操作 failfast cluster模式 快速失败一次调用失败了 failsafe 有异常忽略 failback失败后自动记录请求 forking 并行调用 broadcast 逐个调用 动态代理策略: Javassist 动态字节码技术 SPI 一个接口多个实现如何调用 在MAT-INF 的某个文件内提供好接口的实现类 自动加载 ​ zookeeper]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F09SpringMVC%2F</url>
    <content type="text"><![CDATA[SpringMVC1Spring MVC执行的流程​ Tomcat启动的时候 会去加载 DispatcherServlet 并且StartUp1也就是初始化启动的时候加载,然后拿到配置的mvc.xml的配置文件 里面配置了对应的Controller的包路径,讲这些类加载到容器内,并且将对应的RequestMaping保存 请求过来时 DispatchServlet监听到 通过Url路由到对应的Controller执行对应的方法,方法执行完 返回后找到对应的视图解析器 然后解析 然后返回页面.]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F12MySql%2F</url>
    <content type="text"><![CDATA[1索引1.1MySql页的概念页结构图 1.1.1索引介绍 索引的本质 索引是排序好的一种数据结构,提高Mysql的查询效率 1.1.2索引分类 聚集索引 主键索引:主键为聚集索引且一张表只能有一个聚集索引 聚集索引包括了主键和剩余列的数据,索引的顺序 与数据的逻辑顺序一致,聚集索引存储了表内的所有的数据 是逻辑顺序还是物理顺序 这个不同的书上写的也不同???? 非聚集索引 以下索引的用法及简单概念暂时不写了 普通索引 唯一索引 全文索引 组合索引 注意 1:MyISAM的存储引擎只存储了数据在磁盘的地址地址 ​ MyISAM只有一种索引 也成为了非聚集索引 也是为了和InnoDB的聚集索引区分开来 假设表一共有三列 以第一列为索引 那么存储结构如上,每个叶子节点只存储了指向当前行地址的指针. 2: 而Innodb 是主键索引和数据存储在一起的 ,又称为索引表 ​ ​ 如上表三列可以看出 InnoDB的每个叶子节点 存储的是当前所有列的数据,所以当通过主键查找的时候 非常的快,InnoDB每页的大小为16K所以当索引查找的时候,直接加载当前索引所在的页 然后在内存内查找,又因为内存内存储的是有序的 有可以通过比如二分法之类的来提高效率. 辅助索引 又称为二级所以 非聚集索引 辅助索引与MyISAM的存储引擎比较相似 但是不同的是MyISAM存储的是数据的物理地址 而辅助索引 索引的是主键的值,所以当非主键索引查找的时候 如果查询的列 比如 select b,c from t_b where b=1此时只有b为索引 但是需要查询出来c的值 这个时候 通过二级索引查找 定位到当前对应的主键索引的值 然后再去主键索引表内查找出对应的值,这个操作也称为回表.所以在提高查询效率的时候 可以适当的根据查询的列建立组合索引 这样可以避免回表 为什么InnoDB主键为整形 自增,不推荐UUID? 存储空间 字符串笔整形的大 排序问题 比较大小的时候 需要为Asci码 问答:为什么要使用B+树的变种? 减少范围查询的查询次数? InnoDB是一种索引组织表 索引和数据存储在一起 ##1.2 索引的数据结构 索引结构 二叉树 顺序增长的情况下 会变成链表 查找效率低 Has 红黑树 :是一种平衡树 虽然可以自动平衡 但是在区间查找的情况不好查 数据量大的时候 树的深度是非常深的 所以查询的次数会越来越多 B+Tree 聚集索引: MySql使用了一种B+Tree树的一种变种,非叶子节点不存储数据,叶子节点按顺序排序顺序存储 并且每个叶子节点有一哥指针指向下一个节点 非聚集索引 所有的叶子节点不存储数据 只存储当前的索引和主键索引的地址 查询到之后再去主键索引里查找这个操作称为回表,所以当建索引的时候 尽量使用组合索引,但是组合索引要遵循最左的原则,Mysql在比较索引的时候 是从左到右一个个比较的 using index condition 索引条件下推 当前索引包含这个列的数据 在索引内过滤掉之后 然后再去回表 不用在回表后再去筛选 可以减少回表次数 回表 就是在另外一个索引查询到数据后 再到主键索引内查询响应的数据 索引的最左原则 MySql 8之前 索引只有升序索引,所以Order by的字段如果是 有Desc的话 也不会完全按照索引排序 exta fileSort 2事务读未提交 读已提交 可重复度 串行执行 3锁]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F13JavaIO%2F</url>
    <content type="text"><![CDATA[IOBIO : BlockIO NIO Channels Buffers Selectors AIO Aync 基于事件的异步回调机制]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F%E7%90%86%E8%B4%A2%E4%B8%9A%E5%8A%A1%E4%BD%BF%E7%94%A8%E5%88%B0%E7%9A%84%E6%8A%80%E6%9C%AF%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[1Redis的使用场景业务配置在API接口很多地方会有利息计算 页面显示 够买 等等 都需要很多业务参数参与判断 业务参数后台维护,且业务参数不经常变动,所以业务参数都是存于Redis减少查询数据库的次数 数据一致性 比如还款当提交还款的时候就将还款 防止并发还款 首先将还款初始状态更新为还款中 update LoanRepayment set stauts=&#39;Repaying&#39;where status=&#39;init&#39; ​ 这个时候如果返回受影响的行数是1的话那么就成功了 ​ 比如赎回操作 首先发起一次赎回会生成一笔赎回记录 并且在够买记录上减掉响应的钱,这里如果并发的问题有可能会出现钱减成负数了,因为先查询后判断会出现并发问题,所以在赎回的时候 这个时候可以使用SQL 更新的时候加Where条件来解决,持有的金额减掉要赎回的金额必须大于等于0 这样就算并发了会产生多条记录,但是钱不会表少, 赎回这个操作不会立马完成 后面还有很多操作 赎回第一步操作是生成一个赎回申请, 一个赎回申请有可能会对应很多够买记录的赎回,比如说我赎回一万块,这个一万块对饮很多够买记录,每个够买记录赎回的时候要对应一条赎回记录, 每个赎回记录上也会记录赎回申请的Id, 这个时候根据规则去遍历债权 一直sum到一万块 然后记录每一条债券的Id 这个时候要同事插入赎回申请和赎回记录 两张表 这里开启事务,保证数据一致性, 赎回记录插入的时候 每一条都要去原始债持有金额-赎回的金额 必须大于等于0 防止并发的时候金额减成负数. 然后这边自动任务去查询所有的赎回中的赎回记录 然后开始处理将状态设置为处理中,如果出现异常的话 就解锁 设置为未处理的状态, 赎回要去调用支付中心的 生成一个交易流水的单据,这个单据的refId是我这边的RedeemId, 创建交易单 一般我这边会先查询一次然后再申请创建,支付中心那边也要保住这个交易单的幂等性, 交易单创建完成后 我这边就可以将赎回变成赎回完成了,支付中心那边就会对账户进行转账 ##合同生成 ​ 一个标的有是对应很多份合同,一开始标是一个个开标 每次生成四五分合同速度还可以接受,后来变成了批次开标每次开标的时候需要很长时间,ajax又设置了超时时间,所以经常会看到出现错误的情况 也不知道是不是成功了,一开始没有引入MQ的时候 是基于内存队列来做的,开标成功后往队列添加一个Id,然后另起一个线程一直循环扫描这个队列没有数据的话就休眠,有数据的话就去处理,但是这种不保险,重启一下就没有了,又要去加自动任务去判断这些标是否生成了合同没有的再补偿, 后来我就把消息都发送到MQ里 RabbitMQ也提供了Confirm的机制 但是这里不能因为发送失败了 标开标失败也不合适,毕竟开标生成一系列的东西都在一个事务内,所以我这里加了一个消息表 消息表的操作跟开标的动作在一个事务内 开标后添加一条数据 然后再事务外结束后发送MQ如果MQ返回成功修改为已发送 发送失败设置为发送失败, 然后自动任务重试去发送这条消息. 另外一个消费端来消费这条消息,消费端为了保证不重复生成,可以利用唯一索引来处理,每个标每个类型的合同只允许生成一份. 实时数据备份多线程 多队列上传 多线程实现内存队列 ​ ​ ​]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F00Java%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[String 不可变 Stringbuff 线程安全的 Stringbuild 线程不安全 Java 异常体系 Error 是程序员无法处理的 Exception 程序可以处理的异常 ​ 又分为RuntimeEexception 和非RuntimeException 必须被捕获的 如IOException SQLException ClassNotFoundException]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2019%2F09%2F07%2F01%E6%B6%88%E6%81%AF%E4%B8%AD%E9%97%B4%E4%BB%B6%20%2F</url>
    <content type="text"><![CDATA[消息队列1为什么使用消息队列以及消息队列带来的缺点1:为什么使用消息队列 解耦 系统A比如说是订单系统 订单创建成功后要去扣库存 要去通知配送系统 此时如果有新的系统接入的话那么又需要去改A系统的代码,A系统还需要去考虑服务调用失败的重试问题等等,加入消息队列A系统相当于生产者,其他的系统相当于消费者A系统只需要保证自己产生的消息成功发送到MQ即可,所有的消费者订阅这个消息 自行消费这样就解耦了! 削峰 比如秒杀这样的场景 在短时间内会有大量的请求,但是单台Mysql的处理能力有效 毕竟他需要跟磁盘去打交道I/O的开销很大,如果请求量过大,导致MySql宕机了,那么整个的系统就瘫痪了,引入消息队列,消息队列的吞吐量远远高于MySql的,虽然在高峰的时期消息会有所积压 但是毕竟是高峰时间 短暂过后把消息处理掉,还是可以接受的! 异步 用户发送一个请求进来 这个请求会有一操作比较耗时 ,让用户等几秒钟得到返回肯定是不现实的,所以中间加一层MQ,MQ 操作比较快所以本来需要2S的现在可以在毫秒内返回用户结果,然后这边消费者再去处理当前的消息 2:引入消息队列后带来的缺点 降低系统的可用性,许多系统 都依赖于消息队列来处理业务,一旦消息队列服务宕机那么所有的系统都瘫痪了,所以保证消息队列的高可用是必须要考虑的 提高的开发的难度,和复杂度,消息生产者需要确保消息必须发出去?消费者要确保消息不重复消费?比如消息的顺序性! 一致性问题, 本来 A =&gt;B =&gt;C 调用全部成功了才会返回成功,现在引入了消息队列,A发送消息成功了返回了成功,但是B C都失败了,现在用户觉得成功了. 这也是问题,但是如果你的场景要求强一致性 那就需要引入分布式事务,这个代价太高了,一般选用最终一致性来解决 .比如 加中间状态,回调 自动任务 2消息队列的技术选型 ActiveMQ 吞吐量万级 RabbitMQ 吞吐量万级,延时微妙级别,提供了友好的UI界面, 配置后可以做到消息0丢失 Kafka 分布式,支持高可用 吞吐量十万级别 RocketMQ 阿里巴巴的做背书 而且是Java的如果可以啃源码自己掌控程度比较搞 3保证消息队列的高可用性1:RabbitMQ的高可用架构 普通集群 这种集群模式 每个实例上都会去其他机器上同步当前的元数据 但是实际的数据还是存在某一个实例上,实际上没有达到分布式,如果当前某一个实例宕机了 这一部分数据就会丢失了,当然可以设置RabbitMQ的持久化,但是在宕机的期间 消费者还是消费不到数据的 也没有达到高可用,而且每次发送消息的时候 各个实例之间还会有大量的通信,这种方式其实是用来提升吞吐性的 镜像集群 这种模式,每个节点上都会存储这个消息的数据,其中任何一个宕机都可以从其他的节点获取到数据,但是这种也有弊端 如果当消息数量达到了当前内存的最大值 无法容纳了 可能也只有通过增加物理内存来解决了,不是分布式的 带来的缺点2:Kafka的高可用架构 kafka的一个topic(可以把他理解为一个Queue),但是一个topic可以拥有多个partition 可以指定多个partition,数量和服务器的数量相当. kafka通过副本的机制来保证高可用,也就是说每个topic 下的partition都有一个副本,其实kafka是将两个partition都看做事副本 他会通过选举的方式来选出来一个leader 另外一个称为follower,当发生故障的时候 follower变成leader 写数据的时候 leader会将数据同步到follower上去 这里如果数据还没有同步到follower上的时候 副本挂了 这个时候数据其实还是不一致的,这里可以设置ack ack有三种方式 其中一种是 登所有的follower同步完成后返回ack 然后leader这边返回生产者写入消息成功 这样就保证了 leader和follower的数据一致 4怎么保证消息不重复消费或者消息消费的幂等性1:幂等性由消费者来保证 消费的时候 消费端记录一个消息表,做一个唯一索引,如果下次消费到这个数据的时候插入就会报错 或者每次消费之前先做一次查询 但是这里要保证是单线程来消费 多线程并发 查询后再插入的话也有可能会重复消费 目前项目够买连升的时候,需要调用支付中心的接口,但是每次支付中心不一定都是成功的,或者支付中心成功了,我这边没有收到成功,支付中心处理的时候,需要每次在我申请的时候先查询一下我这个RefId RefType是否有对应的单据 有单据的话 直接返回我单据Id 表示已经创建. 也可以用状态 比如说拿到消息 第一步先将单据状态修改为处理中,如果这次处理失败了,发一条重试的消息 重试的时候 只处理处理中的 5怎么保证消息不丢失1:RabbitMQ如何保证消息不丢失? 生产者将消息弄丢了,比如生成者在订单创建完成了 然后发送到MQ的时候自己挂了 订单成功了 但是消息没有发出去? RabbitMQ支持事务 可以在发送的时候开启事务 收到MQ的回复后才算成功 否则这边执行回滚操作,但是如此下来 吞吐能力大大降低.所以一般不使用. 订单创建成功后 本地维护一个状态或者维护一个消息表,如果发送的时候成功了 那么状态更改为已发送,否则的话 自动任务重试未发生的订单. 这里存在一个问题 MQ已经保存成功消息了 但是在返回的时候 自己挂了导致自己没有更新状态 这个时候会重复去发消息,这就又回到了幂等性的问题,消费者保证消费的幂等性就好了. RabbitMQ的Confirm模式,RabbitMQ在接收到消息的时候 会异步回调你的一个接口,告诉你消息成功或者失败.如果失败了 生产者再重新发送, Confirm模式和事务模式的不同在于 事务是同步的,Confirm是异步的保证了吞吐量 RabbitMQ把消息弄丢了 消息发送成功了,生产者也接收到成功的消息了 但是MQ重启了,消息丢了,这个时候可以开启MQ的持久化,持久化 要设置Queue的持久化 和发送消息的持久化,只设置前者的话 只是持久化了元数据,实际数据没有持久化,要设置deliveryMode=2这样才会将数据持久化, 这里可以配合发送端的Confirm模式来使用,持久化了才Ack应答,否则不应答 就可以保证消息不丢失了 消费者自己把数据弄丢了? 消费者消费到了某一条数据但是还没有处理完就挂了 此时RabbitMQ认为你已经消费了那么数据就丢了 将ack设置为手动提交的 自己处理完了才会提交消费成功 6保证消息队列消费的顺序性1:出错的场景 RabbitMQ 一个Queue 多个Consumer 顺序肯定乱 或者一个Consumer 内部多线程处理 虽然一个Queuen内的消息消费后就没有了,但是内多多线程处理的时候 线程的执行顺序是不固定的 创建多个Queue 一个Queue对应一个Consumer 需要顺序执行的都在一个Queue中 Kafka 一个topic 一个 partition,一个partition至多对应一个Consumer ,内部多线程处理一样会出现顺序错误 内部创建多个内存队列 每个内存Queue对应一个线程 ,这里要根据具体的业务区分发好对应的内存队列,发送消息的时候 需要顺序性的用同样的Key 同样的Key会分发到同一个Partition上 # RabbitMQ的使用]]></content>
  </entry>
  <entry>
    <title><![CDATA[Spring_Cloud_服务划分及服务调用]]></title>
    <url>%2F2019%2F08%2F02%2F%E6%9C%8D%E5%8A%A1%E5%88%92%E5%88%86%E5%8F%8A%E6%9C%8D%E5%8A%A1%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[#服务拆分服务调用 ###1.模块划分 product-common 定义所有共有的对象 如 QO ,VO , Interface asdas QO VO这里定义的内部服务对其他服务调用 提供的Rest接口查询和返回 Interface 所有对外暴露的服务的接口 供product-service实现和product-fegin继承以fegin对外提供服务 product-fegin定义了所有对外暴露的接口 继承了product-common 需要使用product服务的模块只需要引入product-fegin的依赖就可以了 product-service 这里是product-service的实现 controller所有服务的实现 model所有实体对象DataObject API这里API可以称作为边缘服务 是提供给移动端 PC端调用的 这里的输入输出 已经自己Service需要定义自己的DTO和Servie2.服务调用的三种方式 1234567891011121314151617181920 String result = ""; //三种调用方式(需要将URL写死 不利于扩展) RestTemplate template = new RestTemplate();// String result = template.getForObject("http://localhost:8080/product/msg", String.class); //第二种方式 使用loanBalancer 选择一个服务 组装url// ServiceInstance service = loadBalancer.choose("PRODUCT");// try &#123;// URI uri = new URI("http://"+service.getHost()+":"+service.getPort()+"/order/msg");//// result= template.getForObject(uri,String.class);//// &#125; catch (Exception e) &#123;// e.printStackTrace();// &#125; //第三种方式 注册一个BeanRestTemplate 并且使用注解LoadBalance// result = restTemplate.getForObject("http://Product/product/msg", String.class); result = testMessageService.getMessage(); return result; 3.统一配置中心3.1 配置中心服务端​ 新建Config-Server 添加注解@EnableDiscoveryClient @EnableConfigServer 引入依赖: 12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-server&lt;/artifactId&gt; &lt;/dependency&gt; 配置yml 12345678910111213141516server: port: 8082spring: application: name: config-server cloud: config: server: git: uri: https://gitee.com/caolinfei/spring-cloud-config username: 308245591@qq.com password: caolinfei666!eureka: client: service-url: defaultZone: http://eureka1:8761/eureka/ http://localhost:8082/order-dev.yml http://{url}:{port}/{labe} - {filename} - {profile} 格式 lable git的分支 filename文件名称 profile环境变量 后缀名支持三种格式 .json .yml .properties 注意:当使用环境变量的配置时候 默认会将主配置文件加载并且合并 3.2 客户端使用配置中心 加入依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-client&lt;/artifactId&gt; &lt;/dependency&gt; 将Application.yml修改为bootstrap.yml 并且Eureka的配置要放在bootstrap.yml yml配置如下 12345678910111213141516171819202122spring: application: name: order cloud: config: discovery: #配置中心ID service-id: CONFIG-SERVER #启用注册中心发现 enabled: true profile: $&#123;spring.profiles.active&#125; profiles: active: devlogging: level: org.springframework.cloud.openfeign: debugeureka: client: service-url: defualtZone: http://eureka1:8761/eureka/ 3.3 基于RabbitMQ Spring-Cloud_Bus 实现自动刷新配置文件3.3.1服务端搭建服务 客户端读取Config_Server的文件 实现原理 Client端和Condif-Server端共同连接到MQ已达到消息共享 引入依赖 12345//这里如果是使用Kafka 将amqp换成..就好了 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; * 这里遇到了Source文件夹下的yml配置文件 不会编译到target classes 下 需要添加以下配置 1234567891011121314&lt;!--&lt;resources&gt;--&gt; &lt;!--&lt;resource&gt;--&gt; &lt;!--&lt;directory&gt;src/main/java&lt;/directory&gt;--&gt; &lt;!--&lt;includes&gt;--&gt; &lt;!--&lt;include&gt;**/*.*&lt;/include&gt;--&gt; &lt;!--&lt;/includes&gt;--&gt; &lt;!--&lt;/resource&gt;--&gt; &lt;!--&lt;resource&gt;--&gt; &lt;!--&lt;directory&gt;src/main/resources&lt;/directory&gt;--&gt; &lt;!--&lt;includes&gt;--&gt; &lt;!--&lt;include&gt;**/*.*&lt;/include&gt;--&gt; &lt;!--&lt;/includes&gt;--&gt; &lt;!--&lt;/resource&gt;--&gt; &lt;!--&lt;/resources&gt;--&gt; * 服务端配置: 1234567891011121314151617181920 application: name: config-server cloud: config: server: git: uri: https://gitee.com/caolinfei/spring-cloud-config username: 308245591@qq.com password: caolinfei666! #这里的缺省值为localhost 5761 guest guest# rabbitmq:# host: 127.0.0.1# password: guest# username: guesteureka: client: service-url: defaultZone: http://eureka1:8761/eureka/server: port: 8082 * 客户端使用的时候配置文件需要开启Config Server 并且客户端的配置文件需要命名为`BootStrap.yml`因为SpringBoot 默认以此文件第一个加载 1234567891011spring: application: name: order cloud: config: discovery: #配置中心ID service-id: CONFIG-SERVER #启用注册中心发现 enabled: true profile: dev 做到这一步 `Config_Client`已经可以读取到`Config_Server`的配置文件了 但是现在还没有办法实时更新下面我们再进行整改 `Config_Server`提供了对外刷新的接口 我们暴露出去 手动调用一下看看看是否刷新 配置如下 ##### 3.3.2服务端改造 实现自动刷新 Config_Server改造配置文件下增加暴露接口配置 12345management: endpoints: web: exposure: include: "*" 客户端改造 如果你的RabbitMQ默认的配置端口不是5672 或者用户名密码不是guest guest 你还需要配置用户名密码 12345678910111213配置类上需要加上`@RefreshScope`代表刷新的范围#加入配置文件AMQP&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; yml: # rabbitmq:# username: guest# password: guest# host: 127.0.0.1# port: 5762 gitee 上修改配置文件 然后用PostMan 请求接口 actuator/bus-refresh 可以看到消息队列有一条消息 这个时候等消费完 直接访问 客户端的配置文件就可以看到配置自动更新了,但是这种每次手动刷新的方式 并不是我们想要的 Git 一般都会提供WebHooks的方式 netapp.cn 申请一个内网穿透工具 将域名映射为本地ConfigServer的端口 Config服务端添加依赖: 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-config-monitor&lt;/artifactId&gt; &lt;/dependency&gt; * Gitee配置申请的`URL`/monitor]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring_Cloud_Eureka使用]]></title>
    <url>%2F2019%2F07%2F30%2FEureka%2F</url>
    <content type="text"><![CDATA[Eureka简介 Spring Boot版本 2.0.8.RELEASE Spring Cloud 版本 Finchley.SR2 Server端 123456789101112&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-server&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;/dependencies&gt; ​ 2: @EnableEurekaServer 添加注解在启动类上. ​ 3: 配置文件: 12345678910111213141516171819202122eureka: client: service-url: #作为客户端时向其他Eureka注册自己 以达到集群共享的目的 defaultZone: http://localhost:8761/eureka #EnableEurekaServer注解默认包括Client #所以这里要进行设置 # 设置不注册自身 register-with-eureka: false #读取配置中心数据 默认未tue fetch-registry: false #配置当前应用的名称 server: #Eureka的自我保护模式关闭 #当一个服务90s内没有发送心跳 就剔除掉 开启自我保护的话就会进入到自我保护模式 不注销 开发环境可以选择关闭 不太理解啥意思 enable-self-preservation: falsespring: application: name: eureka_server#当前应用端口server: port: 8761 4: 客户端使用 ​ 1:导入依赖 说明 原因是Finchley.SR1版本spring-cloud-starter-netflix-eureka-client里面不在包含spring-boot-starter-web依赖 旧版只有web一种模式，默认使用web。新版还包含webflux，需新增依赖spring-boot-starter-web 或者``spring-boot-starter-webflux 123456789101112&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-netflix-eureka-client&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt; ​ 2:添加注解 ​ @EnableDiscoveryClient ​ 3配置: 1234567891011121314151617181920eureka: client: service-url: #集群的情况下 已","隔开 客户端往多个Eureka注册 多个Eureka #之间两两相互注册 defualtZone: http://localhost:8761/eureka# instance:配置在EurekaServer上点击连接访问的地址# hostname: hellowordspring: application: name: clientserver: port: 9701 eureka: client: service-url: defaultZone: http://eureka1:8761/eureka instance: prefer-ip-address: true instance-id: $&#123;spring.cloud.client.ip-address&#125;:$&#123;server.port&#125; ​ Eureka集群注意事项: ​ 如果使用了Eureka1,eureka2 配置Host这种方式设置集群 时一定要刷新 ipconfig /flushdns 否则回注册不上 列表显示IP 使用IP注册 Eureka的高可用 集群配置 ​ 两台Eureka相互注册 以达到资源共享 ​ 注意事项: eureka集群available-replicas不为空需满足如下条件： 1.不能用localhost比如： eureka.client.serviceUrl.defaultZone=http://localhost:8761/eureka/ 要采用： eureka.instance.hostname=eureka1 eureka.client.serviceUrl.defaultZone=http://eureka2:8762/eureka/ `eureka.instance.hostname=eureka2 eureka.client.serviceUrl.defaultZone=http://eureka1:8761/eureka/` 这里要注意hostname也要一致 spring.application.name 要一直 3.相互注册要开启： eureka.client.register-with-eureka=true eureka.client.fetch-registry=true Instance Status列显示Ip eureka.instance.prefer-ip-address=true 这个可以不开启 这里开启了IP注册 但是使用的hostname 会出现在 unavailable-replicas 这里有坑 eureka.instance.instance-id={spring.cloud.client.ip-address}:${server.port} spring2.0已经将 spring.cloud.client.ipaddress 修改为spring.cloud.client.ip-address* 相信很多小伙伴在实验的时候都会出现这样一个问题：节点出现在 unavailable-replicas 下。下面我们来说一下可能的几种原因： 原因一：prefer-ip-address 配置项设置错误 比如，8761服务器设置了prefer-ip-address: true，那么它注册到 8761和 8762服务器时应该使用 defaultZone:http://yourIP:8761/eureka/ ，但此时可以发现使用的仍然是 hostname 名，导致错误发生。 另一种原因是，三个8761、8762 都设置了prefer-ip-address: true，导致最后解析出来的 hostname 都是相同的IP，使副本不可用。 原因二：register-with-eureka 配置项设置错误 看网上很多博客和资料都把此项设置成了 false，此时 eureka 不会注册到其他服务器上，所以出现错误。 原因三：其他原因 还有一些其他原因大家可以参考这里：Eureka高可用，节点均出现在unavailable-replicas下https://blog.csdn.net/liupeifeng3514/article/details/85273961 更改Eureka实例ID香草Netflix Eureka实例注册了与其主机名相同的ID（即每个主机只有一个服务）。Spring Cloud Eureka提供了一个明智的默认，如下所示：${spring.cloud.client.hostname}:${spring.application.name}:${spring.application.instance_id:${server.port}}}。例如myhost:myappname:8080。 使用Spring Cloud，您可以通过在eureka.instance.instanceId中提供唯一的标识符来覆盖此。例如： application.yml 123eureka: instance: instanceId: $&#123;spring.application.name&#125;:$&#123;vcap.application.instance_id:$&#123;spring.application.instance_id:$&#123;random.value&#125;&#125;&#125;]]></content>
      <categories>
        <category>SpringCloud</category>
      </categories>
      <tags>
        <tag>SpringCloud</tag>
      </tags>
  </entry>
</search>
